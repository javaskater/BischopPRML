# 138 Linear Basis models
* Equation 3.3 with the bias parameter in the $\Sigma$: $\Phi_0(X) = 1$
  * X vector of diemension D
  * y (regression) of dimension 1
# 139
* eq 36 Sigmo√Ød function see graph at [Wikipedia](https://en.wikipedia.org/wiki/Sigmoid_function)
# 140
* Equation 3.9 p 140 was given (like written in RED on the left margin) by Equation 1.89 in Chapter 1 (p 47)
* [Unimodal](https://en.wikipedia.org/wiki/Unimodality) for a distribution means which has a single Peak
* [Multivariate t](https://en.wikipedia.org/wiki/Multivariate_normal_distribution) if each of the $X_i; i \in 1...D$ is a univariate distribution
* Precision is the inverse of variance ($var = \sigma^2$) that is $\beta =\frac{1}{\sigma^2}$
* for each $t_n$, $\mu_n = w^T \times \Phi(x_n)$ the value we compare $t_n$ to.
  * Equation 3_12
* $\Phi$ is given the likehood function is $ln(p(t| w,\beta))$
# 141
* Section 1.2.4 (page 29 or 49/758) we already did the calculation (we have to minimize the sum of Squares)
* the Nabla operator is written by convention on one line, so the use of $\Phi(x_n)^T$
# 142
*  (MxN) x (NxM) = M x M 
*  $(M \times M)^{-1} \times (M \times N)$ gives $M \times N$ and **t** = $(t_1, ..., t_N)^T$ if of $N\times1$ dimension
  * which gives us a $M \times 1$ vector of $W_{ML}$ coefficients $(w_{ML_0}, ... , w_{ML_{M-1}})^T$
* A projection on $\phi_0, \phi_1, ...,\phi_{M-1}$ is a **Linear Combination** of those vectors
  * here through the parameters $w_0, w_1, ..., w_{M-1}$
# 144 paragraph 3.1.3
